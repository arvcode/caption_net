{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet\n",
    "##### References : \n",
    "##### https://learnopencv.com/efficientnet-theory-code/\n",
    "##### https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "##### https://learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/\n",
    "##### https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/arv/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "model=torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b2', pretrained=True, scriptable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-01 13:25:51--  https://github.com/qubvel/efficientnet/raw/master/misc/panda.jpg\n",
      "Resolving github.com (github.com)... 13.250.177.223\n",
      "Connecting to github.com (github.com)|13.250.177.223|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/qubvel/efficientnet/master/misc/panda.jpg [following]\n",
      "--2021-04-01 13:25:52--  https://raw.githubusercontent.com/qubvel/efficientnet/master/misc/panda.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116068 (113K) [image/jpeg]\n",
      "Saving to: ‘panda.jpg.1’\n",
      "\n",
      "panda.jpg.1         100%[===================>] 113.35K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2021-04-01 13:25:52 (36.4 MB/s) - ‘panda.jpg.1’ saved [116068/116068]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/qubvel/efficientnet/raw/master/misc/panda.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open('panda.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-01 13:25:58--  https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31565 (31K) [text/plain]\n",
      "Saving to: ‘labels_map.txt.1’\n",
      "\n",
      "labels_map.txt.1    100%[===================>]  30.83K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2021-04-01 13:25:58 (6.07 MB/s) - ‘labels_map.txt.1’ saved [31565/31565]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map=json.load(open('labels_map.txt'))\n",
    "labels_map=[labels_map[str(i)] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224\n",
    "tfms=transforms.Compose([transforms.Resize(image_size),\n",
    "                         transforms.CenterCrop(image_size),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=tfms(img).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits=model(img)\n",
    "preds=torch.topk(logits,k=5).indices.squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca           (95.41%)\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens         (0.09%)\n",
      "ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus                 (0.06%)\n",
      "earthstar                                                                   (0.05%)\n",
      "badger                                                                      (0.04%)\n"
     ]
    }
   ],
   "source": [
    "for idx in preds:\n",
    "    label=labels_map[idx]\n",
    "    prob=torch.softmax(logits,dim=1)[0,idx].item()\n",
    "    print('{:<75} ({:.2f}%)'.format(label, prob*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to ONNX format\n",
    "ONNX_PATH='efficientnetb2.onnx'\n",
    "torch.onnx.export(model,img,ONNX_PATH,input_names=['input'],\n",
    "                 output_names=['output'],export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model=onnx.load(ONNX_PATH)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch2trt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3f7e7e224fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch2trt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch2trt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch2trt'"
     ]
    }
   ],
   "source": [
    "#from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER=trt.Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engine(onnx_file_path):\n",
    "    builder=trt.Builder(TRT_LOGGER)\n",
    "    network=builder.create_network()\n",
    "    parser=trt.OnnxParser(network,TRT_LOGGER)\n",
    "    \n",
    "    builder.max_workspace_size=1<<20\n",
    "    builder.max_batch_size=1\n",
    "    if builder.platform_has_fast_fp16:\n",
    "        builder.fp16_mode=True\n",
    "    \n",
    "    with open(onnx_file_path,'rb') as model:\n",
    "        parser.parse(model.read())\n",
    "    \n",
    "    engine=builder.build_cuda_engine(network)\n",
    "    #context=engine.create_execution_context()\n",
    "    \n",
    "    return engine#,context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5542c8a902a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5542c8a902a9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#engine,context=build_engine(ONNX_PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mONNX_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbinding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinding_is_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_binding_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #engine,context=build_engine(ONNX_PATH)\n",
    "    engine=build_engine(ONNX_PATH)\n",
    "    for binding in engine:\n",
    "        if engine.binding_is_input(binding):\n",
    "            input_shape=engine.get_binding_shape(binding)\n",
    "            input_size=trt.volume(input_shape)*engine.max_batch_size*np.dtype(np.float32).itemsize\n",
    "            device_input=cuda.mem_alloc(input_size)\n",
    "        else:\n",
    "            output_shape=engine.get_binding_shape(binding)\n",
    "            host_output=cuda.pagelocked_empty(trt.volume(output_shape)* engine.max_batch_size, dtype=np.float)\n",
    "            device_output=cuda_mem_alloc(host_output.nbytes)\n",
    "            \n",
    "    stream=cuda.Stream()\n",
    "    \n",
    "    host_input=np.array(img)\n",
    "    cuda.memcpy_htod_async(device_input,device_output,stream)\n",
    "    \n",
    "    stream.synchronize()\n",
    "    \n",
    "    output_data=torch.Tensor(host_output).reshape(engine.max_batch_size, output_shape[0])\n",
    "\n",
    "    \n",
    "main()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
